{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75232424-a1c0-4a39-fe3b-4efad3707541"
   },
   "source": [
    "# WORDS EMBEDDING - SONGS IN ENGLISH CORPUS\n",
    "## - PARAMETROS OPTIMIZADOS PARA MEJOR ENTRENAMIENTO\n",
    "## - PRUEBAS CON DIFERENTES CLUSTERS (KMEANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5639af0e-aa64-74bd-de5c-b6f5c50b041f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "import sklearn.manifold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15369545-997e-e9f9-b1ac-02dff0031be3"
   },
   "source": [
    "Though non english artists were removed, the dataset contained Hindi lyrics of Lata Mangeshkar written in English. Therefore, I decided to remove all songs sung by her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "61f9b0e5-e203-22c7-4cab-457133f7b80a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv(\"data/songdata.csv\", header=0)\n",
    "#songs.head()\n",
    "songs = songs[songs.artist != 'Lata Mangeshkar']\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f436501-4d68-c1d7-f418-5b13462780ef"
   },
   "source": [
    "To train the word2vec model, we first need to build its vocabulary. To do that, I iterated over each song and added it to an array that can later be fed to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOY A EXTRAER MAS DIMENSIONES (100) PARA QUE SEA MÁS PRECISO Y BAJAR EL CONTEXT_SIZE  A 5 PARA EVITAR SOBRE-ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADEMAS VOY A USAR EL TOKINAZER PARA QUITAR LA PUNTUACION Y VER MEJOR LAS COMPARACINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "a6a957b3-8bec-4d26-6cc4-6a19d3d24f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57618\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text_corpus = []\n",
    "for song in songs['text']:\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+') #para dividir por words y quitar puntuacion\n",
    "    lower_case = song.lower()\n",
    "    tokens_sin_puntuacion = tokenizer.tokenize(lower_case)\n",
    "    \n",
    "    text_corpus.append(tokens_sin_puntuacion)\n",
    "\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 100\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 5\n",
    "\n",
    "\n",
    "downsampling = 1e-1\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n",
    "\n",
    "songs2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")\n",
    "\n",
    "songs2vec.build_vocab(text_corpus)\n",
    "print (len(text_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AÑADO MAS EPOCHS PARA QUE ENTRENE MEJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "18363422-5ac9-77aa-1f58-cd745000ac6c"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "songs2vec.train(text_corpus, total_examples=songs2vec.corpus_count, epochs=5)\n",
    "\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "\n",
    "songs2vec.save(os.path.join(\"trained\", \"songs2vectors.w2v\"))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0690a4a-10f5-d2ce-9dee-480a8b77d114"
   },
   "outputs": [],
   "source": [
    "songs2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"songs2vectors.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"sweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"angel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODAS LAS ANTERIORES LAS HA HECHO MUY BIEN PORQUE ESTÁN RELACIONADAS CON CANCIONES! LAS SIGUIENTES LE VA A COSTAR UN POCO MÁS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"espresso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LO MISMO VA A PASAR CON LAS WORDS OUT OF CONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words out of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.doesnt_match(\"happiness love joy hate\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.wv.doesnt_match(\"breakfast milk lunch dinner\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2vec.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "#queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic distance between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = songs2vec.wv.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{0} es a {1}, lo que {2} es a {3}\".format(start1, end1, start2, end2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"paris\", \"france\", \"alabama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"paris\", \"france\", \"london\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con estas diferentes palabras que hemos probado podemos ver como para palabras similares a lo que hay en una canción, lo hace muy bien, pero para palabras extrañas musicalmente hablando (como paises y capitales) le cuesta BASTANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULO DE NORMALIZED SUM VECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRIMERO CREAMOS UNA COLUMNA EN EL DATAFRAME QUE CONTENGA LAS LETRAS LIMPIAS SIN PUNTUACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_clean=[]\n",
    "for row in text_corpus:\n",
    "    lyrics_clean.append(' '.join(row))\n",
    "    \n",
    "songs['lyrics_clean']=lyrics_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9f0fe3f-cbf8-e751-9d9a-acbaec2f0aad"
   },
   "source": [
    "With the word vector embeddings in place, it is now time to calculate the normalised vector sum of each song. This process can take some time since it has to be done for each of 57,000 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d11b30f-e526-dd24-9084-d5f7dfd00058"
   },
   "outputs": [],
   "source": [
    "def songVector(row):\n",
    "    vector_sum = 0\n",
    "    words = row.lower().split()\n",
    "    for word in words:\n",
    "        vector_sum = vector_sum + songs2vec[word]\n",
    "    vector_sum = vector_sum.reshape(1,-1)\n",
    "    normalised_vector_sum = sklearn.preprocessing.normalize(vector_sum)\n",
    "    return normalised_vector_sum\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "songs['song_vector'] = songs['lyrics_clean'].apply(songVector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "303a0106-9112-d06e-393c-8affc71a1e41"
   },
   "source": [
    "**t-sne and random song selection** \n",
    "\n",
    "The songs have 50 dimensions each. Application of t-sne is memory intensive and hence it is slightly easier on the computer to use a random sample of the 57,000 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "028d8c5b-a7df-30a0-a1dc-fbb1442c77f4"
   },
   "outputs": [],
   "source": [
    "song_vectors = []\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(songs, test_size = 0.9)\n",
    "\n",
    "\n",
    "for song_vector in train['song_vector']:\n",
    "    song_vectors.append(song_vector)\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af7db425-5b23-e106-738c-86039164ed82"
   },
   "source": [
    "I had a fairly measly 4gb machine and wasn't able to generate a more accurate model. However, one can play around with the number of iterations, learning rate and other factors to fit the model better. If you have too many dimensions (~300+), it might make sense to use PCA first and then t-sne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "031560ae-0460-2fed-6ef3-6fc5840db6ad"
   },
   "outputs": [],
   "source": [
    "X = np.array(song_vectors).reshape((5761, 100))\n",
    "\n",
    "start_time = time.time()\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, n_iter=250, random_state=0, verbose=2)\n",
    "\n",
    "all_word_vectors_matrix_2d = tsne.fit_transform(X)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "245d45c2-4d47-7b36-83c1-065a04d6112e"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(all_word_vectors_matrix_2d,columns=['X','Y'])\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "train.head()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06e23870-3718-ac53-cf69-19efcc7983b0"
   },
   "source": [
    "Joining two dataframes to obtain each song's corresponding X,Y co-ordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "774acb91-c804-4593-e5b3-a0cfc1de274c"
   },
   "outputs": [],
   "source": [
    "two_dimensional_songs = pd.concat([train, df], axis=1)\n",
    "\n",
    "two_dimensional_songs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3be297f-924a-0026-de2a-532330697763"
   },
   "source": [
    "**Plotting the results**\n",
    "\n",
    "Using plotly, I plotted the results so that it becomes easier to explore similar songs based on their colors and clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d94bd43-4efb-8c1c-1646-561134c2eccd"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig=px.scatter(two_dimensional_songs, x='X', y='Y', color='artist')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(two_dimensional_songs, x='X', y='Y', z='song',\n",
    "                color='artist')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING CON KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8d6fd7b-5044-30d1-283a-517a462888c3"
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "X = np.array(song_vectors).reshape((5761, 100))\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=3, \n",
    "                        random_state=42).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(two_dimensional_songs, x=\"X\", y=\"Y\",\n",
    "                 hover_data=['artist', 'song'],\n",
    "                color=kmeans.labels_)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(two_dimensional_songs, x='X', y='Y', z='artist',\n",
    "                color=kmeans.labels_)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PINTANDO LOS DISTINTOS CLUSTERS DE KMEANS PODEMOS ENCONTRAR QUE CANCIONES SIMILARES EN TEMATICA SE AGRUPAN JUNTAS\n",
    "- Por ejemplo las canciones de amor suelen estar en el cluster amarilo (Adam Sandler - Best Friend, whiteny Houston - For the love of you)\n",
    "- En el azul hay música más\"independiente\" que quizá creando más clusters podriamos categorizar mejor (probamos a continuacion)\n",
    "- En el rosa parece haber música más energética como raps y rocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS CON 15 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=15, \n",
    "                        random_state=42).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(two_dimensional_songs, x=\"X\", y=\"Y\",\n",
    "                 hover_data=['artist', 'song'],\n",
    "                color=kmeans.labels_)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQUI PODEMOS VER QUE LA AGRUPACION TIENE SENTIDO CON RESPECTO A LAS CARACTERISTICAS X E Y. EL COLOR PASA DE CLARO A OSCURO FORMANDO DISTINTOS CLUSTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALIZANDO LAS LETRAS DE LAS CANCIONES DE CADA CLUSTER SE PODRIA VER QUE MUCHAS PALABRAS SE REPITEN PARA LAS CANCIONES DE UN MISMO CLUSTER"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 1,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
