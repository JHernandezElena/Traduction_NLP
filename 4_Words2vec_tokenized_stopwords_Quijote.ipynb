{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75232424-a1c0-4a39-fe3b-4efad3707541",
    "colab_type": "text",
    "id": "918NcvM_sM8U"
   },
   "source": [
    "The aim of this notebook is to make use of the word2vec model to find similar songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC - Exploracion con un Corpus de canciones en Español usando tokenizer y stopwords para crear el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto va a ser menos exacto que los anteriores porque hay menos palabras. Pero es interesante verlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "5639af0e-aa64-74bd-de5c-b6f5c50b041f",
    "colab": {},
    "colab_type": "code",
    "id": "flidHJ8TsM8V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "import sklearn.manifold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15369545-997e-e9f9-b1ac-02dff0031be3",
    "colab_type": "text",
    "id": "nRjV5XcFsM8Y"
   },
   "source": [
    "Cargamos las el quijote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/quijote.txt\", \"r\", encoding=\"utf8\") \n",
    "content =f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiamos los caractes raros y quitamos acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "clean_file = []\n",
    "for k in content.split(\"\\n\"):\n",
    "    k = unidecode(k) #quitamos los acentos\n",
    "    clean_file.append(re.sub(r\"[^a-zA-Z0-9]+\", ' ', k)) #limpiamos las lineas de caracteres raros\n",
    "    \n",
    "for line in clean_file:  #quitamos las lineas vacias\n",
    "    if line == '':\n",
    "        clean_file.remove(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f436501-4d68-c1d7-f418-5b13462780ef",
    "colab_type": "text",
    "id": "y_PeY9S2sM8b"
   },
   "source": [
    "To train the word2vec model, we first need to build its vocabulary. To do that, I iterated over each song and added it to an array that can later be fed to the model.\n",
    "\n",
    "#### Usamos tokenizer y stopwords para tener un mejor vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text_corpus = []\n",
    "for line in clean_file:\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+') #para dividir por words y quitar puntuacion\n",
    "    lower_case = line.lower()\n",
    "    tokens_sin_puntuacion = tokenizer.tokenize(lower_case)\n",
    "    tokens = [i for i in tokens_sin_puntuacion if (len(i)>1) and i not in stopwords.words('spanish')] #quitamos stop words\n",
    "    \n",
    "    text_corpus.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_cell_guid": "a6a957b3-8bec-4d26-6cc4-6a19d3d24f7d",
    "colab": {},
    "colab_type": "code",
    "id": "UoGo_kUmsM8c",
    "outputId": "9c50f32b-1cff-4c53-c72d-a99b0329a7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32339\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 50\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "\n",
    "downsampling = 1e-1\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n",
    "\n",
    "songs2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")\n",
    "\n",
    "songs2vec.build_vocab(text_corpus)\n",
    "print (len(text_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydJQHDOmfD-L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.6159968376159668 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "songs2vec.train(text_corpus, total_examples=songs2vec.corpus_count, epochs=2)\n",
    "\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "\n",
    "songs2vec.save(os.path.join(\"trained\", \"songs2vectors.w2v\"))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "_cell_guid": "e0690a4a-10f5-d2ce-9dee-480a8b77d114",
    "colab": {},
    "colab_type": "code",
    "id": "lJBbRHyMsM8f"
   },
   "outputs": [],
   "source": [
    "songs2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"songs2vectors.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYVCqMIdsM8h"
   },
   "source": [
    "#### Let's explore our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6zeibuesM8h"
   },
   "source": [
    "Find similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Syo_JMRdsM8h",
    "outputId": "a0f55484-532d-4d82-b608-1aabaef5b66e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sancho', 0.957434356212616),\n",
       " ('asi', 0.9564037322998047),\n",
       " ('cura', 0.9529216289520264),\n",
       " ('dila', 0.9478768110275269),\n",
       " ('pues', 0.9369694590568542),\n",
       " ('duque', 0.9366923570632935),\n",
       " ('voz', 0.9357013702392578),\n",
       " ('senora', 0.9349565505981445),\n",
       " ('duquesa', 0.9339219331741333),\n",
       " ('barbero', 0.9335750341415405)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.most_similar(\"quijote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWYF4B6LsM8k",
    "outputId": "8d8e3883-5a3c-47dc-fe44-5191c235801e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asi', 0.9668811559677124),\n",
       " ('quijote', 0.9574342966079712),\n",
       " ('cura', 0.9552509784698486),\n",
       " ('pues', 0.945313036441803),\n",
       " ('decir', 0.9427224397659302),\n",
       " ('senora', 0.9385666847229004),\n",
       " ('si', 0.9359698295593262),\n",
       " ('verdad', 0.9331722259521484),\n",
       " ('habia', 0.9328069686889648),\n",
       " ('bien', 0.9322810769081116)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.most_similar(\"sancho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pie', 0.9992693066596985),\n",
       " ('palabra', 0.999201774597168),\n",
       " ('mesmo', 0.9991865754127502),\n",
       " ('primo', 0.9990447759628296),\n",
       " ('cuenta', 0.998988687992096),\n",
       " ('nunca', 0.9989795088768005),\n",
       " ('lugar', 0.9989739656448364),\n",
       " ('iba', 0.9988583326339722),\n",
       " ('camino', 0.9988481998443604),\n",
       " ('ama', 0.9988390207290649)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.most_similar(\"caballo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mismo', 0.9994622468948364),\n",
       " ('mucha', 0.9994367957115173),\n",
       " ('canonigo', 0.9994223713874817),\n",
       " ('primero', 0.9993078708648682),\n",
       " ('fin', 0.9992329478263855),\n",
       " ('entender', 0.9992038607597351),\n",
       " ('nunca', 0.9991317391395569),\n",
       " ('libro', 0.9990227222442627),\n",
       " ('tenia', 0.9989996552467346),\n",
       " ('contento', 0.9989832043647766)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.most_similar(\"camino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dijese', 0.9994610548019409),\n",
       " ('aventura', 0.9994574189186096),\n",
       " ('mucha', 0.9993853569030762),\n",
       " ('entender', 0.9993103742599487),\n",
       " ('mismo', 0.9992714524269104),\n",
       " ('duena', 0.9992218613624573),\n",
       " ('desa', 0.9992120265960693),\n",
       " ('nombre', 0.9991418123245239),\n",
       " ('adonde', 0.9991415739059448),\n",
       " ('oyo', 0.9991327524185181)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.most_similar(\"libro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRMNr3qDsM8m"
   },
   "source": [
    "Words out of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLbf-TTXsM8n",
    "outputId": "512968d0-1ccc-45e9-8837-0f29422852df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhern\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aventura'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.doesnt_match(\"sancho quijote aventura\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'camino'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.doesnt_match(\"camino senora senor\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bebida'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.wv.doesnt_match(\"comida bebida árbol\".split()) #se equivoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1636A6VLsM8p",
    "outputId": "cdb11a99-2777-4646-fed8-2b33907b30f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhern\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vuesa', 0.9589300751686096),\n",
       " ('mio', 0.95602947473526),\n",
       " ('digo', 0.956020176410675),\n",
       " ('senor', 0.9536997079849243),\n",
       " ('decir', 0.9526917934417725),\n",
       " ('respondio', 0.9521059989929199),\n",
       " ('dijo', 0.9520894885063171),\n",
       " ('bien', 0.9513685703277588),\n",
       " ('dice', 0.9496554136276245),\n",
       " ('dios', 0.9490358829498291)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2vec.most_similar(positive=['sancho', 'panza'], negative=['quijote'])\n",
    "#queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1K-wzTtDsM8w"
   },
   "source": [
    "Semantic distance between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muvD22cJsM8x"
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = songs2vec.wv.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{0} es a {1}, lo que {2} es a {3}\".format(start1, end1, start2, end2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Tjyq8a7sM82",
    "outputId": "618a0981-6f6a-485b-b71d-948ebc7038d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sancho es a panza, lo que quijote es a don\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"sancho\", \"panza\", \"don\") #bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libro es a historia, lo que llegando es a camino\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"libro\", \"historia\", \"camino\") #mas o menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verso es a poesia, lo que ciencias es a cancion\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"verso\", \"poesia\", \"cancion\") #mas o menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBBMTaxysM9Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 1,
  "_is_fork": false,
  "colab": {
   "name": "4b_TEXT_word2vec-songs-recommendation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
